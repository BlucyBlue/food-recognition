{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\r\n",
      "  Downloading kaggle-1.6.3.tar.gz (84 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m84.5/84.5 kB\u001B[0m \u001B[31m678.8 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: six>=1.10 in /Users/rastkopavlovic/miniconda3/lib/python3.11/site-packages (from kaggle) (1.16.0)\r\n",
      "Requirement already satisfied: certifi in /Users/rastkopavlovic/miniconda3/lib/python3.11/site-packages (from kaggle) (2023.7.22)\r\n",
      "Requirement already satisfied: python-dateutil in /Users/rastkopavlovic/miniconda3/lib/python3.11/site-packages (from kaggle) (2.8.2)\r\n",
      "Requirement already satisfied: requests in /Users/rastkopavlovic/miniconda3/lib/python3.11/site-packages (from kaggle) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/rastkopavlovic/miniconda3/lib/python3.11/site-packages (from kaggle) (4.65.0)\r\n",
      "Collecting python-slugify (from kaggle)\r\n",
      "  Using cached python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\r\n",
      "Requirement already satisfied: urllib3 in /Users/rastkopavlovic/miniconda3/lib/python3.11/site-packages (from kaggle) (1.26.16)\r\n",
      "Requirement already satisfied: bleach in /Users/rastkopavlovic/miniconda3/lib/python3.11/site-packages (from kaggle) (4.1.0)\r\n",
      "Requirement already satisfied: packaging in /Users/rastkopavlovic/miniconda3/lib/python3.11/site-packages (from bleach->kaggle) (23.0)\r\n",
      "Requirement already satisfied: webencodings in /Users/rastkopavlovic/miniconda3/lib/python3.11/site-packages (from bleach->kaggle) (0.5.1)\r\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\r\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rastkopavlovic/miniconda3/lib/python3.11/site-packages (from requests->kaggle) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rastkopavlovic/miniconda3/lib/python3.11/site-packages (from requests->kaggle) (3.4)\r\n",
      "Building wheels for collected packages: kaggle\r\n",
      "  Building wheel for kaggle (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for kaggle: filename=kaggle-1.6.3-py3-none-any.whl size=111919 sha256=8eb2d50cfb1f103b019ac1f6e637f34e1995fee84f37e2ae0d297f3b019b60c6\r\n",
      "  Stored in directory: /Users/rastkopavlovic/Library/Caches/pip/wheels/c5/94/5b/08d5bb9b7b78401fa26da264ef32d72bfbd9cb74641c65169b\r\n",
      "Successfully built kaggle\r\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\r\n",
      "Successfully installed kaggle-1.6.3 python-slugify-8.0.1 text-unidecode-1.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For Google Colab only\n",
    "from google.colab import files\n",
    "files.upload()  # Upload kaggle.json here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# kaggle key activation\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data retrieval\n",
    "!kaggle datasets download -d trolukovich/food11-image-dataset\n",
    "!unzip -q food11-image-dataset.zip -d dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_images(images, titles=None, ncols=3):\n",
    "    n = len(images)\n",
    "    nrows = n // ncols + (1 if n % ncols else 0)\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 5 * nrows))\n",
    "    axs = axs.flatten()\n",
    "    for i, img_path in enumerate(images):\n",
    "        img = Image.open(img_path)\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].axis('off')\n",
    "        if titles:\n",
    "            axs[i].set_title(titles[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show first few images from a specific food category\n",
    "food_category = 'dataset/training/0'  # Change as needed\n",
    "image_files = [os.path.join(food_category, f) for f in os.listdir(food_category)[:9]]\n",
    "show_images(image_files)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Analyzing dataset distribution.\n",
    "\n",
    "categories = os.listdir('dataset/training')\n",
    "counts = [len(os.listdir(os.path.join('dataset/training', c))) for c in categories]\n",
    "\n",
    "sns.barplot(x=categories, y=counts)\n",
    "plt.xlabel('Food Categories')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Distribution of Food Categories in Training Set')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def plot_image_size_distribution(directory):\n",
    "    widths, heights = [], []\n",
    "    for subdir in os.listdir(directory):\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            for file in os.listdir(subdir_path):\n",
    "                file_path = os.path.join(subdir_path, file)\n",
    "                with Image.open(file_path) as img:\n",
    "                    width, height = img.size\n",
    "                    widths.append(width)\n",
    "                    heights.append(height)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(widths, bins=50, color='skyblue')\n",
    "    plt.title('Width Distribution')\n",
    "    plt.xlabel('Width')\n",
    "    plt.ylabel('Number of Images')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(heights, bins=50, color='salmon')\n",
    "    plt.title('Height Distribution')\n",
    "    plt.xlabel('Height')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_image_size_distribution('dataset/training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def show_sample_images_from_each_category(directory, samples_per_category=3):\n",
    "    categories = os.listdir(directory)\n",
    "    fig, axs = plt.subplots(len(categories), samples_per_category, figsize=(15, len(categories)*3))\n",
    "\n",
    "    for i, category in enumerate(categories):\n",
    "        category_path = os.path.join(directory, category)\n",
    "        image_files = random.sample(os.listdir(category_path), samples_per_category)\n",
    "        image_files = [os.path.join(category_path, f) for f in image_files]\n",
    "\n",
    "        for j, img_path in enumerate(image_files):\n",
    "            img = Image.open(img_path)\n",
    "            axs[i, j].imshow(img)\n",
    "            axs[i, j].axis('off')\n",
    "            if j == 0:\n",
    "                axs[i, j].set_ylabel(category)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "show_sample_images_from_each_category('dataset/training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Set your dataset directories\n",
    "train_dir = 'dataset/training'\n",
    "validation_dir = 'dataset/validation'\n",
    "test_dir = 'dataset/evaluation'\n",
    "\n",
    "# Define image size and batch size\n",
    "img_height, img_width = 224, 224  # You can adjust these values as per your model's requirement\n",
    "batch_size = 32\n",
    "\n",
    "# Rescaling factor for normalization (1./255 is common for RGB images)\n",
    "rescale_factor = 1./255\n",
    "\n",
    "# Create Image Data Generators for resizing and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=rescale_factor,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=rescale_factor)\n",
    "\n",
    "# Load images from directory and apply transformations\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # Use 'binary' for binary classification\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # Use 'binary' for binary classification\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # Use 'binary' for binary classification\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}