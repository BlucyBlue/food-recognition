{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For Google Colab only\n",
    "from google.colab import files\n",
    "files.upload()  # Upload kaggle.json here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# kaggle key activation\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data retrieval\n",
    "!kaggle datasets download -d sainikhileshreddy/food-recognition-2022\n",
    "!unzip -q food-recognition-2022.zip -d dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "def show_images(images, titles=None, ncols=3):\n",
    "    n = len(images)\n",
    "    nrows = n // ncols + (1 if n % ncols else 0)\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 5 * nrows))\n",
    "    axs = axs.flatten()\n",
    "    for i, img_path in enumerate(images):\n",
    "        img = Image.open(img_path)\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].axis('off')\n",
    "        if titles:\n",
    "            axs[i].set_title(titles[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show first few images from a specific food category\n",
    "food_category = './dataset/raw_data/public_training_set_release_2.0/images'  # Change as needed\n",
    "image_files = [os.path.join(food_category, f) for f in os.listdir(food_category)[:9]]\n",
    "show_images(image_files)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_dataset(image_dir, annotations_file, batch_size, img_height, img_width):\n",
    "    # Read and parse the JSON file\n",
    "    with open(annotations_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Create a mapping from ID to all metadata\n",
    "    id_to_metadata = {item['id']: item for item in data['categories']}\n",
    "\n",
    "    # Initialize lists to store file paths and metadata\n",
    "    file_paths = []\n",
    "    metadata_list = []\n",
    "\n",
    "    # Iterate through the directory and match each image with its metadata\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_id = int(filename.split('.')[0])\n",
    "            image_metadata = id_to_metadata.get(image_id)\n",
    "            if image_metadata:\n",
    "                file_paths.append(os.path.join(image_dir, filename))\n",
    "                metadata_list.append(image_metadata)\n",
    "\n",
    "    # Load images and preprocess them\n",
    "    def load_and_preprocess_image(path, metadata):\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [img_height, img_width])\n",
    "        image /= 255.0  # Normalize to [0,1] range\n",
    "\n",
    "        # Prepare the metadata. Here we are converting it to a tensor.\n",
    "        # You might need to adjust this depending on how you plan to use the metadata.\n",
    "        metadata_tensor = tf.convert_to_tensor([metadata['id'],\n",
    "                                               metadata['name'],\n",
    "                                               metadata['name_readable'],\n",
    "                                               metadata['supercategory']], dtype=tf.string)\n",
    "        return image, metadata_tensor\n",
    "\n",
    "    # Create a dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, metadata_list))\n",
    "    dataset = dataset.map(load_and_preprocess_image)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define image size and batch size\n",
    "img_height, img_width = 224, 224  # You can adjust these values as per your model's requirement\n",
    "batch_size = 32\n",
    "\n",
    "# Rescaling factor for normalization (1./255 is common for RGB images)\n",
    "rescale_factor = 1./255"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "num_classes = 11 # num_classes is the number of food categories\n",
    "\n",
    "sequential_model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluating the models\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, test_generator):\n",
    "    test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "    predictions = model.predict(test_generator)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = test_generator.classes\n",
    "    print(f\"Test accuracy: {test_acc}\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Plotting function for training/validation curves\n",
    "def plot_learning_curves(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()),1])\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0,1.0])\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "train_data = create_dataset('./dataset/raw_data/public_training_set_release_2.0/images', \n",
    "                            './dataset/raw_data/public_training_set_release_2.0/annotations.json', batch_size, img_height, img_width)\n",
    "validation_data = create_dataset('./dataset/raw_data/public_vaidation_set_2.0/images', \n",
    "                            './dataset/raw_data/public_validation_set_2.0/annotations.json', batch_size, img_height, img_width)\n",
    "test_data = create_dataset('./dataset/raw_data/public_test_set_release_2.0/images', \n",
    "                            './dataset/raw_data/public_test_set_release_2.0/annotations.json', batch_size, img_height, img_width)\n",
    "compile_model(sequential_model)\n",
    "sequential_model_history = sequential_model.fit(train_data, validation_data=validation_data)\n",
    "plot_learning_curves(sequential_model_history)\n",
    "evaluate_model(sequential_model, test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}